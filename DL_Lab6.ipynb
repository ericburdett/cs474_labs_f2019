{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE8ElXCulbYL",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "## Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "## There are two parts of this lab:\n",
        "###  1.   Wiring up a basic sequence-to-sequence computation graph\n",
        "###  2.   Implementing your own GRU cell.\n",
        "\n",
        "\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l7bdZWxvJrsx",
        "outputId": "0e687e94-96a5-47f3-9f48-302e1465752a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "shake_file = unidecode.unidecode(open('./text_files/tiny_shakespeare.txt').read())\n",
        "shake_file_len = len(shake_file)\n",
        "print('shake_file_len=', shake_file_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-20 05:56:34--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 3.214.17.10, 52.2.48.133, 34.205.95.128, ...\n",
            "Connecting to piazza.com (piazza.com)|3.214.17.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2019-10-20 05:56:34--  https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)... 13.224.217.42, 13.224.217.34, 13.224.217.219, ...\n",
            "Connecting to d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)|13.224.217.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "\r./text_files.tar.gz   0%[                    ]       0  --.-KB/s               \r./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-10-20 05:56:34 (45.4 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "file_len = 2579888\n",
            "shake_file_len= 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxBeKeNjJ0NQ",
        "outputId": "21e0c127-d871-4a63-9ed5-d64a20e18170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "\n",
        "def shake_random_chunk():\n",
        "  start_index = random.randint(0, shake_file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return shake_file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())\n",
        "print(shake_random_chunk())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rom his thin sickly face. For \n",
            "a moment he relapsed into his old Gollum-manner. 'We are famisshed, yes \n",
            "famisshed we are. precious,' he said. 'What is it they eats? Have they nice \n",
            "fisshes? ' His tongu\n",
            "h. Then all stand still;\n",
            "On: those that think it is unlawful business\n",
            "I am about, let them depart.\n",
            "\n",
            "LEONTES:\n",
            "Proceed:\n",
            "No foot shall stir.\n",
            "\n",
            "PAULINA:\n",
            "Music, awake her; strike!\n",
            "'Tis time; descend; be ston\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "On0_WitWJ99e",
        "outputId": "ea3fe333-e2fb-4d17-eb4f-4862c0065565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create a custom GRU cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aavAv50ZKQ-F",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Each layer does the following:\n",
        "# r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "# z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "# n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "# h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "# Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    \n",
        "    self.w_ir = nn.Linear(input_size, hidden_size)\n",
        "    self.w_hr = nn.Linear(hidden_size, hidden_size)\n",
        "    self.w_iz = nn.Linear(input_size, hidden_size)\n",
        "    self.w_hz = nn.Linear(hidden_size, hidden_size)\n",
        "    self.w_in = nn.Linear(input_size, hidden_size)\n",
        "    self.w_hn = nn.Linear(hidden_size, hidden_size)\n",
        "    \n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "  \n",
        "  def forward(self, inputs, hidden):\n",
        "    \n",
        "    r_t = self.sigmoid(self.w_ir(inputs) + self.w_hr(hidden))\n",
        "    z_t = self.sigmoid(self.w_iz(inputs) + self.w_hz(hidden))\n",
        "    \n",
        "    n_t = self.tanh(self.w_in(inputs) + torch.mul(r_t, self.w_hn(hidden)))\n",
        "    h_t = torch.mul(1 - z_t, n_t) + torch.mul(z_t, hidden)\n",
        "    \n",
        "    return h_t[-1:], h_t\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77ihHoC0gcEn",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create an RNN class that extends from nn.Module.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d6tNdEnzWj5F",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    self.embed = nn.Embedding(n_characters, hidden_size)\n",
        "    self.gru = GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=n_layers)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
        "    \n",
        "    # more stuff here...\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    embedding = self.embed(input_char).unsqueeze(0).unsqueeze(0)\n",
        "    out_decoded, hidden = self.gru(embedding, hidden)\n",
        "    linear_out = self.linear(out_decoded)\n",
        "    output = self.relu(linear_out)\n",
        "\n",
        "    # by reviewing the documentation, construct a forward function that properly uses the output\n",
        "    # of the GRU\n",
        "\n",
        "    # stuff here\n",
        "    \n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.n_layers, 1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrhXghEPKD-5",
        "colab": {}
      },
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target\n",
        "\n",
        "def shake_random_training_set():\n",
        "  chunk = shake_random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill in the pieces.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ALC3Pf8Kbsi",
        "outputId": "6832b720-c519-42b3-ade3-502652a3d9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_size = n_characters\n",
        "hidden_size = 200\n",
        "output_size = n_characters\n",
        "n_layers = 3\n",
        "  \n",
        "decoder = RNN(input_size=input_size, hidden_size=hidden_size,\n",
        "              output_size=output_size, n_layers=n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "objective = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(inp, target):\n",
        "  # initialize hidden state\n",
        "  hidden = decoder.init_hidden()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  \n",
        "  loss = 0\n",
        "  \n",
        "  for char, next_char in zip(inp, target):\n",
        "\n",
        "    # make prediction, get next hidden state\n",
        "    pred, hidden = decoder(char, hidden)\n",
        "\n",
        "    # compute the loss\n",
        "    loss += objective(pred.squeeze(0), next_char.unsqueeze(0))\n",
        "\n",
        "  # update the network\n",
        "  loss.backward()\n",
        "    \n",
        "  decoder_optimizer.step()\n",
        "    \n",
        "  return loss / len(inp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom GRU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFFOB86v-2Ar",
        "colab_type": "code",
        "outputId": "c1cc70e8-17ba-489a-9bde-93c7c04116eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B-bp-OZ1KjNh",
        "colab": {}
      },
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  ## initialize hidden state, initialize other useful variables\n",
        "    # your code here\n",
        "  ## /\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    prime_tensor = char_tensor(prime_str)\n",
        "\n",
        "    # Priming\n",
        "    hidden = torch.zeros(n_layers, 1, hidden_size)\n",
        "    character = char_tensor('')\n",
        "    for char in prime_tensor:\n",
        "      character, hidden = decoder(char, hidden)\n",
        "\n",
        "    probs = F.softmax(character.squeeze(0).squeeze(0) / temperature, dim=0)\n",
        "    character = torch.multinomial(probs, 1).squeeze(0)\n",
        "\n",
        "    for _ in range(predict_len):\n",
        "      character, hidden = decoder(character, hidden)\n",
        "      probs = F.softmax(character.squeeze(0).squeeze(0) / temperature, dim=0)\n",
        "      character = torch.multinomial(probs, 1).squeeze(0)\n",
        "      prime_str += all_characters[character.item()]\n",
        "\n",
        "\n",
        "  return prime_str.replace('\\n', ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs gave.\n",
        "\n",
        "**TODO:** \n",
        "\n",
        "**DONE:**\n",
        "* Create some cool output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-nXFeCmdKodw",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import gc\n",
        "n_epochs = 4000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "# hidden_size = 200\n",
        "# n_layers = 3\n",
        "# lr = 0.001\n",
        " \n",
        "# decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "# decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xKfozqw-6eqb",
        "outputId": "482dd730-ed84-4c00-83c6-52ae54c9c995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  \n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "    print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "    print(evaluate('Wh', 100, .6), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6e93cac0e769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n_epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1oJGHL_zdjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Lord of the Rings Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(range(len(all_losses)) * plot_every, all_losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ee0so6aKJ5L8",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2nkTDSNuOmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb90730b-fdbd-46bb-9f9a-98c0c951372b"
      },
      "source": [
        "input_size = n_characters\n",
        "hidden_size = 200\n",
        "output_size = n_characters\n",
        "n_layers = 3\n",
        "  \n",
        "decoder = RNN(input_size=input_size, hidden_size=hidden_size,\n",
        "              output_size=output_size, n_layers=n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "objective = nn.CrossEntropyLoss()\n",
        "\n",
        "shake_start = time.time()\n",
        "shake_all_losses = []\n",
        "shake_loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  \n",
        "  shake_loss_ = train(*shake_random_training_set())       \n",
        "  shake_loss_avg += shake_loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "    print('[%s (%d %d%%) %.4f]' % (time.time() - shake_start, epoch, epoch / n_epochs * 100, shake_loss_))\n",
        "    print(evaluate('Wh', 100, .6), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      shake_all_losses.append(shake_loss_avg / plot_every)\n",
        "      shake_loss_avg = 0"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom GRU\n",
            "[35.80942416191101 (100 2%) 2.4862]\n",
            "Whd sta, and the that therof pou the cot thats meat the tou thoust the bene me lance pon I int  IBA: 4 \n",
            "\n",
            "[71.38724660873413 (200 5%) 2.3574]\n",
            "Whr hen myo loen ano the you in thease be at the me the of he all sho mou saras that in of thou and fo \n",
            "\n",
            "[107.32283234596252 (300 7%) 2.1115]\n",
            "Whn, you and, you that the mose our beestine tor in iso the man the hean the fort thou the for be to l \n",
            "\n",
            "[142.74453139305115 (400 10%) 2.0327]\n",
            "Whd wein to mad of not thou st weat with the dethems the come the thee sir were an the you had soul th \n",
            "\n",
            "[178.83712458610535 (500 12%) 2.0804]\n",
            "Whr the the him.  COLUCELNIO: So comed that you been this the to me hat the dintose the to will for th \n",
            "\n",
            "[215.12371921539307 (600 15%) 2.0591]\n",
            "Wh houl my a your to the dout come and, we the shall day, Thuse hand shtis may of tre, Thet be my dead \n",
            "\n",
            "[250.76790189743042 (700 17%) 1.9315]\n",
            "Wht hath to so kind the hath the rounds the contristances That and that that the dist and and he crome \n",
            "\n",
            "[286.27036237716675 (800 20%) 2.0646]\n",
            "Whts chow canter it stay it it is all thouse the soan a do shouse unce and his leat hastered a contrer \n",
            "\n",
            "[321.76818656921387 (900 22%) 1.9849]\n",
            "Whster my to mast then ento therees my susted for plours, not resces  Seathinest.  KING RICHARD III: T \n",
            "\n",
            "[357.32065176963806 (1000 25%) 1.8753]\n",
            "Whuence of comelous: I se priend shall to hath hirs the prainks of and if and shall no lear the poor f \n",
            "\n",
            "[392.48130202293396 (1100 27%) 1.9318]\n",
            "Whre his to seed and strake I am then couse And dease could shall soul strence a bories.  LUCESTIO: Th \n",
            "\n",
            "[427.6337890625 (1200 30%) 1.7861]\n",
            "Wh praints your wasch be what wellow aid a dear enter.  ROMELO: No my stand hame of not, the are the s \n",
            "\n",
            "[463.2118489742279 (1300 32%) 2.0240]\n",
            "Wht I candery dead of the kind and as hath make the lown, The for the care sil mead, and the wercain   \n",
            "\n",
            "[499.19456028938293 (1400 35%) 1.8677]\n",
            "Wht what will no li6e.  ROMEO: So heir with make hen your bord, what fortuent him, flient, The strom h \n",
            "\n",
            "[534.9666395187378 (1500 37%) 2.0523]\n",
            "Wh% let my betured in me she man a would it it as her here as in a prookJ Tchis lords my him in the pa \n",
            "\n",
            "[570.4939527511597 (1600 40%) 1.8742]\n",
            "Whre it, a father.  CAULETHA: But her parts the came of ender, conther.  GRESTER: I fath like the cour \n",
            "\n",
            "[606.0637559890747 (1700 42%) 1.9110]\n",
            "Whch of the warder the senct a sire And me.  KING HERNCENTO: And with my brows the sany the mimented A \n",
            "\n",
            "[641.5293545722961 (1800 45%) 1.9986]\n",
            "Whre your are to peself.  PETRUCHIO: I this had prooman the proppets, and word.  PETRUCHIO: Then here  \n",
            "\n",
            "[677.1380732059479 (1900 47%) 1.7315]\n",
            "Wht and the bathin and here, and with heartion of him ment may Hould shall be this is the struen forth \n",
            "\n",
            "[712.6024041175842 (2000 50%) 1.7975]\n",
            "Wht, Be the most to this for my son fall the coursely, And my so thou lords the come it maYes of the b \n",
            "\n",
            "[748.1748950481415 (2100 52%) 1.9230]\n",
            "Whre ence, the perower that do father house stare The come not prife a wear be perity you father me fo \n",
            "\n",
            "[783.8486018180847 (2200 55%) 2.0001]\n",
            "Whth and and with the rest, her for the here I their be so thou make the crother the weres for the wil \n",
            "\n",
            "[819.7325193881989 (2300 57%) 2.1036]\n",
            "Whch for hence.  LEONTES: And the part of the forted they will the fail.  DUKE O, the prance and not f \n",
            "\n",
            "[855.1781311035156 (2400 60%) 1.7455]\n",
            "Wht I would thou are of think.  CORIO: Thou sir, what my lord: no should but in hath his should him sh \n",
            "\n",
            "[890.714076757431 (2500 62%) 1.8753]\n",
            "Whnd him, and recous as I asser of my father, and my secution, my come.  ERCENIUS: I art by the with a \n",
            "\n",
            "[926.0801150798798 (2600 65%) 1.9161]\n",
            "Wht eyerer here in propers.  LUCENTIO: And my so my make they waters, and fare the fire, And my were d \n",
            "\n",
            "[961.6209754943848 (2700 67%) 1.8572]\n",
            "Whn a more perin; The hearrs do and my do stand his hail I had hear a could and he honess and from wee \n",
            "\n",
            "[997.0262041091919 (2800 70%) 1.5098]\n",
            "Whm here was with say thee stards, And duke thou ha` I had fathers In he wear to this oft the breather \n",
            "\n",
            "[1032.3258302211761 (2900 72%) 1.9502]\n",
            "Whch hear think.  PETRUCHIO: God the tone for their feent the suck, That you chire were hand since you \n",
            "\n",
            "[1067.8999724388123 (3000 75%) 1.8990]\n",
            "Whrence thinks to shall deed.  ROMEO: You had stand it.  MENENIUS: That must shall the mistrant and si \n",
            "\n",
            "[1103.2512454986572 (3100 77%) 1.8899]\n",
            "Wht warry my long the grow of good, More and to the bading of shen and the more, I he had my gracter h \n",
            "\n",
            "[1138.9374170303345 (3200 80%) 1.5102]\n",
            "Wh, the since in the kings to my lord.  DUKE O son, streath, benour here the prown word, And resce, li \n",
            "\n",
            "[1174.4886548519135 (3300 82%) 1.6907]\n",
            "Wht with not bring so from them that thee, To him thee shall not may a fair of your counting, )et the  \n",
            "\n",
            "[1209.7758843898773 (3400 85%) 1.9736]\n",
            "Whre banish your house that I will God your ebperel hold me time assing. so here and speaks of these s \n",
            "\n",
            "[1245.0680801868439 (3500 87%) 1.5097]\n",
            "Wht word not didon: My lord the first to his before they And that the gone the booth of you are the st \n",
            "\n",
            "[1280.5595779418945 (3600 90%) 1.9635]\n",
            "Wht that be  lors, sir, by then a stones in this dife.  MENENIUS: Their child morrers me and that York \n",
            "\n",
            "[1316.1951806545258 (3700 92%) 1.3932]\n",
            "Whch with here, And garder for the sits of the propousing That an him him for a dear seater and but be \n",
            "\n",
            "[1351.7454087734222 (3800 95%) 1.8380]\n",
            "Whre that wear her giers.  CLIcking.  LADY DUKE O, so in the would to his word them the world dost str \n",
            "\n",
            "[1386.94305062294 (3900 97%) 1.6579]\n",
            "Whrefore in harm and face The word in the been thing of them all to your for were To place of him and  \n",
            "\n",
            "[1422.3103227615356 (4000 100%) 2.0628]\n",
            "Wh, be must time, And he dearthy the heart hear me onMy of the pasting to bean, But both, come, by thy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzx2W74xyTpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ea34722d-9a76-4502-87e8-9e2c51af6434"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Shakespeare Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot([i * plot_every for i in range(len(shake_all_losses))], shake_all_losses)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24bFwNviyERA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "0214f1bc-8826-45f1-e3c0-2f51737d4142"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ca\n",
            " canot it to rainst.  HENRY BOLINGART: But to gracious speak her heable me That my lord, I must if it wars nower.  GLOUCESTER: There dound his rest toushal ha/ry semseling him the wear2\tury.  Speen: I sh \n",
            "\n",
            " ca\n",
            " cases me goods not our trust Plight and proces and woman to prewour: Thou starible manglosely, but commanged.  RICHARD: No, so set three welkering to pertuches our looks, And her stain, appear to me awe \n",
            "\n",
            " G\n",
            " Geil say, consusing of the house 3i\"zen, Be made -a world beconsuly to bears as I his beances a sterain.  PETRUCHIO: And your your beding like that Let out, thou is not the miser, And it head, and rung \n",
            "\n",
            " lo\n",
            " lok at with Do tone me and you reads, Part thou are your had Grine throw me, when in the wears to make That part to millenderpelity opon The one you do seaten.  LUCIO: The, good blest in to me, appary.  \n",
            "\n",
            " ra\n",
            " raed to comporign.  PETRUCHIO: I would him is redius do good made To madise and of it instressured This discortal by what would towen your depared That such our wain that we ha_5 is must time That shar, \n",
            "\n",
            " G\n",
            " Gntleman: I had good know me, I come, her hast it well same to me: That at truinge to merein to may held son.  PETRUCHARELL: dos, I haR the better to is tony seeJ blood to them: I soulless you, send fo \n",
            "\n",
            " he\n",
            " heble foul his odes know the hand of your lord thou areming in me=ning of such me: And heady bloodZ&LI hood marcoused The beablour with that a primpess droshed In then warised their pince anding then.   \n",
            "\n",
            " G\n",
            " Gse is: the beary wembrity.  BISHER: It mather uncle secuntion: The hearts componted to be mothers it I depon are In to ditter her proson, and percesson, But this blity of his wared The partices had be \n",
            "\n",
            " I \n",
            " I ail double heir ways to me fliest ears of speet{end bock it mear/y.  Prompeful: I twill of heine shall it my fruth the honour to parted to must one hea: I home her well her and must bence bed their ma \n",
            "\n",
            " ca\n",
            " cae their such, In well and great in than my ore.  RICHARD: To all with hell, bes the haic, Some a may our send by healsE Thou forth the brother his fleshir3 me peacefulish ond make, thou Harcies The he \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkf6B8Fv0nPg",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation:**\n",
        "\n",
        "My Model is doing pretty well at organizing general sentence structure. It's even doing fairly well with punctuation. On the shakespeare dataset, it is creating names (in all caps), followed by a colon to denote a person speaking.\n",
        "\n",
        "Although the model is doing fairly well at creating actual words, including some punctuation"
      ]
    }
  ]
}